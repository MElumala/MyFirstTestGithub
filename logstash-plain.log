[2020-05-28T00:00:18,330][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:00:18,330][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:00:18,385][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:00:18,385][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:00:52,414][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:00:52,417][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:00:52,417][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:00:52,422][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:00:52,900][INFO ][logstash.outputs.file    ][main][659951b347a9a93fa9757201e8129b48ee75d320481a8a133a418750243d5488] Opening file {:path=>"G:/WorkingEnv/ELKStack/logstash-7.7.0/logstash-7.7.0/bin/my_output_text_file"}
[2020-05-28T00:01:05,486][INFO ][logstash.outputs.file    ][main][659951b347a9a93fa9757201e8129b48ee75d320481a8a133a418750243d5488] Closing file G:/WorkingEnv/ELKStack/logstash-7.7.0/logstash-7.7.0/bin/my_output_text_file
[2020-05-28T00:01:22,924][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:01:22,928][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:01:30,451][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:01:30,451][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:01:30,455][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:01:30,455][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:01:54,974][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:01:54,979][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:02:16,492][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:02:16,494][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:02:16,496][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:02:16,501][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:02:28,997][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:02:29,001][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:03:07,026][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:03:07,030][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:03:18,520][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:03:18,520][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:03:18,529][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:03:18,534][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:03:53,068][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:03:53,074][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:04:52,568][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:04:52,573][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:04:52,576][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:04:52,580][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:04:55,112][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:04:55,116][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:06:26,614][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:06:26,620][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:06:26,624][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:06:26,630][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:06:29,150][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:06:29,151][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:07:03,945][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2020-05-28T00:07:08,966][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2020-05-28T00:07:09,157][WARN ][org.logstash.execution.ShutdownWatcherExt] {"inflight_count"=>0, "stalling_threads_info"=>{"other"=>[{"thread_id"=>35, "name"=>"[main]<beats", "current_call"=>"[...]/vendor/bundle/jruby/2.5.0/gems/logstash-input-beats-6.0.9-java/lib/logstash/inputs/beats.rb:197:in `run'"}, {"thread_id"=>31, "name"=>"[main]>worker0", "current_call"=>"[...]/logstash-core/lib/logstash/java_pipeline.rb:279:in `block in start_workers'"}, {"thread_id"=>32, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/2.5.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>33, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/2.5.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>34, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/2.5.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}]}}
[2020-05-28T00:07:09,175][ERROR][org.logstash.execution.ShutdownWatcherExt] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2020-05-28T00:07:14,235][WARN ][org.logstash.execution.ShutdownWatcherExt] {"inflight_count"=>0, "stalling_threads_info"=>{"other"=>[{"thread_id"=>32, "name"=>"[main]>worker1", "current_call"=>"[...]/vendor/bundle/jruby/2.5.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>33, "name"=>"[main]>worker2", "current_call"=>"[...]/vendor/bundle/jruby/2.5.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}, {"thread_id"=>34, "name"=>"[main]>worker3", "current_call"=>"[...]/vendor/bundle/jruby/2.5.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'"}]}}
[2020-05-28T00:07:39,090][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2020-05-28T00:07:39,341][ERROR][org.logstash.Logstash    ] org.jruby.exceptions.ThreadKill
[2020-05-28T00:08:13,211][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2020-05-28T00:08:13,328][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"7.7.0"}
[2020-05-28T00:08:15,798][INFO ][org.reflections.Reflections] Reflections took 41 ms to scan 1 urls, producing 21 keys and 41 values 
[2020-05-28T00:08:18,072][INFO ][logstash.outputs.elasticsearch][main] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2020-05-28T00:08:18,309][WARN ][logstash.outputs.elasticsearch][main] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2020-05-28T00:08:18,361][INFO ][logstash.outputs.elasticsearch][main] ES Output version determined {:es_version=>7}
[2020-05-28T00:08:18,366][WARN ][logstash.outputs.elasticsearch][main] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>7}
[2020-05-28T00:08:18,425][INFO ][logstash.outputs.elasticsearch][main] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["http://localhost:9200"]}
[2020-05-28T00:08:18,489][INFO ][logstash.outputs.elasticsearch][main] Using default mapping template
[2020-05-28T00:08:18,572][INFO ][logstash.outputs.elasticsearch][main] Attempting to install template {:manage_template=>{"index_patterns"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s", "number_of_shards"=>1, "index.lifecycle.name"=>"logstash-policy", "index.lifecycle.rollover_alias"=>"logstash"}, "mappings"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}
[2020-05-28T00:08:18,624][WARN ][org.logstash.instrument.metrics.gauge.LazyDelegatingGauge][main] A gauge metric of an unknown type (org.jruby.specialized.RubyArrayOneObject) has been created for key: cluster_uuids. This may result in invalid serialization.  It is recommended to log an issue to the responsible developer/development team.
[2020-05-28T00:08:18,676][INFO ][logstash.javapipeline    ][main] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50, "pipeline.max_inflight"=>500, "pipeline.sources"=>["G:/WorkingEnv/ELKStack/logstash-7.7.0/logstash-7.7.0/config/mylogstash.conf"], :thread=>"#<Thread:0x5072a5d8 run>"}
[2020-05-28T00:08:19,721][INFO ][logstash.inputs.beats    ][main] Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[2020-05-28T00:08:19,746][INFO ][logstash.javapipeline    ][main] Pipeline started {"pipeline.id"=>"main"}
[2020-05-28T00:08:19,926][INFO ][org.logstash.beats.Server][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] Starting server on port: 5044
[2020-05-28T00:08:19,930][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2020-05-28T00:08:20,328][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2020-05-28T00:09:13,693][INFO ][logstash.outputs.file    ][main][659951b347a9a93fa9757201e8129b48ee75d320481a8a133a418750243d5488] Opening file {:path=>"G:/WorkingEnv/ELKStack/logstash-7.7.0/logstash-7.7.0/bin/my_output_text_file"}
[2020-05-28T00:09:28,594][INFO ][logstash.outputs.file    ][main][659951b347a9a93fa9757201e8129b48ee75d320481a8a133a418750243d5488] Closing file G:/WorkingEnv/ELKStack/logstash-7.7.0/logstash-7.7.0/bin/my_output_text_file
[2020-05-28T00:09:43,979][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:09:43,983][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:10:16,042][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:10:16,045][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:10:50,064][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:10:50,066][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:11:28,122][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:11:28,127][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:12:14,147][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:12:14,150][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:13:16,184][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:13:16,189][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:14:50,233][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:14:50,239][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:16:24,285][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:16:24,290][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:17:58,313][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:17:58,326][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:19:32,365][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:19:32,371][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:21:06,402][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:21:06,404][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:22:40,434][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:22:40,439][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:24:14,458][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:24:14,460][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:25:48,491][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:25:48,497][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:27:22,521][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:27:22,526][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:28:56,542][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] retrying failed action with response code: 503 ({"type"=>"process_cluster_event_timeout_exception", "reason"=>"failed to process cluster event (put-mapping [logstash-2020.05.27-000001/QvWXfIdESROf_fj5-n1sug]) within 30s"})
[2020-05-28T00:28:56,545][INFO ][logstash.outputs.elasticsearch][main][7e66b1cd043d991aacf1505708d679cfced5f87c28641c8a41b599e2c17af505] Retrying individual bulk actions that failed or were rejected by the previous bulk request. {:count=>1}
[2020-05-28T00:29:51,034][INFO ][org.logstash.beats.BeatsHandler][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] [local: 0:0:0:0:0:0:0:1:5044, remote: 0:0:0:0:0:0:0:1:64825] Handling exception: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 71
[2020-05-28T00:29:51,043][WARN ][io.netty.channel.DefaultChannelPipeline][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 71
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:38) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:353) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:66) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at java.lang.Thread.run(Unknown Source) [?:1.8.0_251]
Caused by: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 71
	at org.logstash.beats.Protocol.version(Protocol.java:22) ~[logstash-input-beats-6.0.9.jar:?]
	at org.logstash.beats.BeatsParser.decode(BeatsParser.java:62) ~[logstash-input-beats-6.0.9.jar:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	... 8 more
[2020-05-28T00:29:51,058][INFO ][org.logstash.beats.BeatsHandler][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] [local: 0:0:0:0:0:0:0:1:5044, remote: 0:0:0:0:0:0:0:1:64825] Handling exception: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 69
[2020-05-28T00:29:51,063][WARN ][io.netty.channel.DefaultChannelPipeline][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 69
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:405) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:372) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.access$300(AbstractChannelHandlerContext.java:38) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext$4.run(AbstractChannelHandlerContext.java:236) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:66) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at java.lang.Thread.run(Unknown Source) [?:1.8.0_251]
Caused by: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 69
	at org.logstash.beats.Protocol.version(Protocol.java:22) ~[logstash-input-beats-6.0.9.jar:?]
	at org.logstash.beats.BeatsParser.decode(BeatsParser.java:62) ~[logstash-input-beats-6.0.9.jar:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	... 10 more
[2020-05-28T00:29:51,057][INFO ][org.logstash.beats.BeatsHandler][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] [local: 0:0:0:0:0:0:0:1:5044, remote: 0:0:0:0:0:0:0:1:64824] Handling exception: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 71
[2020-05-28T00:29:51,067][WARN ][io.netty.channel.DefaultChannelPipeline][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 71
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:38) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:353) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:66) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at java.lang.Thread.run(Unknown Source) [?:1.8.0_251]
Caused by: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 71
	at org.logstash.beats.Protocol.version(Protocol.java:22) ~[logstash-input-beats-6.0.9.jar:?]
	at org.logstash.beats.BeatsParser.decode(BeatsParser.java:62) ~[logstash-input-beats-6.0.9.jar:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	... 8 more
[2020-05-28T00:29:51,078][INFO ][org.logstash.beats.BeatsHandler][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] [local: 0:0:0:0:0:0:0:1:5044, remote: 0:0:0:0:0:0:0:1:64824] Handling exception: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 69
[2020-05-28T00:29:51,083][WARN ][io.netty.channel.DefaultChannelPipeline][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 69
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:405) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:372) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.access$300(AbstractChannelHandlerContext.java:38) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext$4.run(AbstractChannelHandlerContext.java:236) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:66) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at java.lang.Thread.run(Unknown Source) [?:1.8.0_251]
Caused by: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 69
	at org.logstash.beats.Protocol.version(Protocol.java:22) ~[logstash-input-beats-6.0.9.jar:?]
	at org.logstash.beats.BeatsParser.decode(BeatsParser.java:62) ~[logstash-input-beats-6.0.9.jar:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	... 10 more
[2020-05-28T00:29:51,095][INFO ][org.logstash.beats.BeatsHandler][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] [local: 0:0:0:0:0:0:0:1:5044, remote: 0:0:0:0:0:0:0:1:64826] Handling exception: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 71
[2020-05-28T00:29:51,106][WARN ][io.netty.channel.DefaultChannelPipeline][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 71
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:38) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:353) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:66) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at java.lang.Thread.run(Unknown Source) [?:1.8.0_251]
Caused by: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 71
	at org.logstash.beats.Protocol.version(Protocol.java:22) ~[logstash-input-beats-6.0.9.jar:?]
	at org.logstash.beats.BeatsParser.decode(BeatsParser.java:62) ~[logstash-input-beats-6.0.9.jar:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	... 8 more
[2020-05-28T00:29:51,118][INFO ][org.logstash.beats.BeatsHandler][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] [local: 0:0:0:0:0:0:0:1:5044, remote: 0:0:0:0:0:0:0:1:64826] Handling exception: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 69
[2020-05-28T00:29:51,121][WARN ][io.netty.channel.DefaultChannelPipeline][main][f8d9a87ab04f687249918cb2299ecfdce54a429d9b6f882b01115301d90a207e] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
io.netty.handler.codec.DecoderException: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 69
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:405) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:372) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext.access$300(AbstractChannelHandlerContext.java:38) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannelHandlerContext$4.run(AbstractChannelHandlerContext.java:236) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:66) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-all-4.1.30.Final.jar:4.1.30.Final]
	at java.lang.Thread.run(Unknown Source) [?:1.8.0_251]
Caused by: org.logstash.beats.InvalidFrameProtocolException: Invalid version of beats protocol: 69
	at org.logstash.beats.Protocol.version(Protocol.java:22) ~[logstash-input-beats-6.0.9.jar:?]
	at org.logstash.beats.BeatsParser.decode(BeatsParser.java:62) ~[logstash-input-beats-6.0.9.jar:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-all-4.1.30.Final.jar:4.1.30.Final]
	... 10 more
[2020-05-28T00:30:12,407][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2020-05-28T00:30:12,792][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2020-05-28T00:30:12,893][ERROR][org.logstash.Logstash    ] org.jruby.exceptions.ThreadKill
